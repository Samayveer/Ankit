{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6z1BRifLyhU"
      },
      "source": [
        "#Imports and Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeWSm0aGmrEW",
        "outputId": "4b3d7617-a4e0-4fba-dc9f-29b9b142c60d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG8Jy2XP-6_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac564ec-221d-4fef-b8c9-466380a10e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bygdoAJs5aEW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn , optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset  # Add this import statement\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "batch = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI8Xu_YlmrEf",
        "outputId": "f223bb4b-1006-4fdb-9d91-6de39f30fe25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_yF1AYcmrEh"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512), antialias=True),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.PILToTensor(),\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512), antialias=True),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.PILToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_d = datasets.ImageFolder(root='/content/drive/MyDrive/PROPOSED_ACNN/PROPOSED_SACNN1/train/cross', transform=train_transform)\n",
        "dot_d = datasets.ImageFolder(root='/content/drive/MyDrive/PROPOSED_ACNN/PROPOSED_SACNN1/train/dot', transform=train_transform)\n"
      ],
      "metadata": {
        "id": "xG60gAP9LHcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_td = datasets.ImageFolder(root='/content/drive/MyDrive/PROPOSED_ACNN/PROPOSED_SACNN1/test/cross', transform=valid_transform)\n",
        "dot_td = datasets.ImageFolder(root='/content/drive/MyDrive/PROPOSED_ACNN/PROPOSED_SACNN1/test/dot', transform=valid_transform)"
      ],
      "metadata": {
        "id": "zqN_4a_ULLtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_d = datasets.ImageFolder(root='/content/drive/MyDrive/train/cross', transform=train_transform)\n",
        "# dot_d = datasets.ImageFolder(root='/content/drive/MyDrive/train/dot', transform=train_transform)"
      ],
      "metadata": {
        "id": "z-zruNGQ-Xtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_td = datasets.ImageFolder(root='/content/drive/MyDrive/test/cross', transform=valid_transform)\n",
        "# dot_td = datasets.ImageFolder(root='/content/drive/MyDrive/test/dot', transform=valid_transform)"
      ],
      "metadata": {
        "id": "yVrdv1EjHHwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MRLYAI7mrEi"
      },
      "outputs": [],
      "source": [
        "class cross_dot(Dataset):\n",
        "    def __init__(self,cross,dot):\n",
        "        self.cross = cross\n",
        "        self.dot   = dot\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        x1=self.cross[index]\n",
        "        x2=self.dot[index]\n",
        "        return x1,x2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cross)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJGKboeXmrEi"
      },
      "outputs": [],
      "source": [
        "test_data = cross_dot(cross_td,dot_td)\n",
        "train_data = cross_dot(cross_d,dot_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9ENtkX9A_Nb"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_data,batch_size=batch,shuffle=False,num_workers=2)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Assuming train_dataset is your complete training dataset\n",
        "train_size = len(train_data)\n",
        "val_size = int(0.1 * train_size)\n",
        "train_size = train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n",
        "\n",
        "# Define your DataLoader for training\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define your DataLoader for validation\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYwpT0HXFzAq",
        "outputId": "18c6f2ff-5109-41ad-ed99-737f1e37d72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfwYu6XDF0mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi"
      ],
      "metadata": {
        "id": "6lnrIhs5LTLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, inplanes, num_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.num_heads = num_heads\n",
        "        assert self.inplanes % self.num_heads == 0, \"inplanes must be divisible by num_heads\"\n",
        "\n",
        "        self.head_dim = self.inplanes // self.num_heads\n",
        "\n",
        "        # Define linear transformations for queries, keys, and values for each head\n",
        "        self.query_heads = nn.ModuleList([nn.Conv2d(self.inplanes, self.head_dim, 1) for _ in range(self.num_heads)])\n",
        "        self.key_heads = nn.ModuleList([nn.Conv2d(self.inplanes, self.head_dim, 1) for _ in range(self.num_heads)])\n",
        "        self.value_heads = nn.ModuleList([nn.Conv2d(self.inplanes, self.head_dim, 1) for _ in range(self.num_heads)])\n",
        "\n",
        "        # Final linear transformation\n",
        "        self.w = nn.Conv2d(self.inplanes, self.inplanes, 1)\n",
        "\n",
        "    def forward(self, xs):\n",
        "        # Apply linear transformations for query, key, value\n",
        "        queries = [self.query_heads[i](xs) for i in range(self.num_heads)]\n",
        "        keys = [self.key_heads[i](xs) for i in range(self.num_heads)]\n",
        "        values = [self.value_heads[i](xs) for i in range(self.num_heads)]\n",
        "\n",
        "        # Prepare query, key, value tensors\n",
        "        queries = [query.view(query.size(0), self.head_dim, -1) for query in queries]\n",
        "        keys = [key.view(key.size(0), self.head_dim, -1) for key in keys]\n",
        "        values = [value.view(value.size(0), self.head_dim, -1) for value in values]\n",
        "\n",
        "        # Compute attention scores\n",
        "        attention_scores = [torch.matmul(queries[i], keys[i].transpose(-2, -1)) / (self.head_dim ** 0.5) for i in range(self.num_heads)]\n",
        "        attention_scores = [F.softmax(score, dim=-1) for score in attention_scores]\n",
        "\n",
        "        # Apply attention to values\n",
        "        head_outputs = [torch.matmul(attention_scores[i], values[i]) for i in range(self.num_heads)]\n",
        "        head_outputs = [output.view(output.size(0), self.head_dim, xs.size(2), xs.size(3)) for output in head_outputs]\n",
        "\n",
        "        # Concatenate head outputs along the channel dimension\n",
        "        multi_head_output = torch.cat(head_outputs, dim=1)\n",
        "\n",
        "        # Final linear transformation\n",
        "        multi_head_output = self.w(multi_head_output)\n",
        "\n",
        "        # Add residual connection\n",
        "        output = xs + multi_head_output\n",
        "        return output\n",
        "\n",
        "class CNNP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNP, self).__init__()\n",
        "        channel = 32\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(1, channel, 5, 1, padding=2),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(1, channel, 7, 1, padding=3),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv7 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv8 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv9 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv10 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.attn = MultiHeadAttention(channel, num_heads=8)\n",
        "        self.pool = nn.AvgPool2d(2, 2)\n",
        "        self.resize = transforms.Resize(512)\n",
        "\n",
        "    def forward(self, images):\n",
        "        out2 = self.conv2(images)\n",
        "        out3 = self.conv3(images)\n",
        "        pool2 = self.pool(self.pool(self.pool(out2)))\n",
        "        pool3 = self.pool(self.pool(self.pool(out3)))\n",
        "\n",
        "        attn2 = self.attn(pool2)\n",
        "        attn3 = self.attn(pool3)\n",
        "\n",
        "        attn2 = self.resize(attn2)\n",
        "        attn3 = self.resize(attn3)\n",
        "\n",
        "        out_f = out3 + attn3 + out2 + attn2\n",
        "        out4 = self.conv4(out_f)\n",
        "        out5 = self.conv5(out4 + out_f)\n",
        "        out6 = self.conv6(out4 + out_f)\n",
        "        out7 = self.conv7(out6 + out_f)\n",
        "        out8 = self.conv8(out7 + out_f)\n",
        "        out9 = self.conv9(out8 + out_f)\n",
        "        out10 = self.conv10(out9 + out_f)\n",
        "\n",
        "        return out10"
      ],
      "metadata": {
        "id": "Dc5klhqO-llW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [4, 8, 16, 32])\n",
        "\n",
        "    # Adjust the DataLoader for the suggested batch size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Initialize the model, loss function, and optimizer with the suggested hyperparameters\n",
        "    model = CNNP().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
        "\n",
        "    epochs = 50\n",
        "    best_val_accuracy = 0.0\n",
        "    patience = 2\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_accuracy_cross_to_dot = 0\n",
        "        total_accuracy_dot_to_cross = 0\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/PROPOSED_ACNN/PROPOSED_SACNN1/model_parameter/model_state_epoch_{epoch + 1}.pth')\n",
        "\n",
        "        for i, (cross, dot) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output_cross_to_dot = model(cross[0].float().to(device))\n",
        "            loss_cross_to_dot = criterion(output_cross_to_dot, dot[0].float().to(device))\n",
        "            loss_cross_to_dot.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            predictions_cross_to_dot = torch.round(output_cross_to_dot).squeeze().float()\n",
        "            correct_cross_to_dot = torch.eq(predictions_cross_to_dot, dot[0].float().to(device).squeeze()).sum().item()\n",
        "            accuracy_cross_to_dot_batch = correct_cross_to_dot / (batch_size * 512 * 512)\n",
        "            total_accuracy_cross_to_dot += accuracy_cross_to_dot_batch\n",
        "\n",
        "        average_accuracy_cross_to_dot = total_accuracy_cross_to_dot / len(train_loader)\n",
        "        print(f'[{epoch + 1}] Cross-to-Dot Average Accuracy: {average_accuracy_cross_to_dot:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            total_val_accuracy_cross_to_dot = 0\n",
        "\n",
        "            for val_cross_img, val_dot_img in val_loader:\n",
        "                val_output_cross_to_dot = model(val_cross_img[0].float().to(device))\n",
        "                val_loss_cross_to_dot = criterion(val_output_cross_to_dot, val_dot_img[0].float().to(device))\n",
        "\n",
        "                val_predictions_cross_to_dot = torch.round(val_output_cross_to_dot).squeeze().float()\n",
        "                val_correct_cross_to_dot = torch.eq(val_predictions_cross_to_dot, val_dot_img[0].float().to(device).squeeze()).sum().item()\n",
        "                val_accuracy_cross_to_dot = val_correct_cross_to_dot / (batch_size * 512 * 512)\n",
        "\n",
        "                total_val_accuracy_cross_to_dot += val_accuracy_cross_to_dot\n",
        "\n",
        "            average_val_accuracy_cross_to_dot = total_val_accuracy_cross_to_dot / len(val_loader)\n",
        "            print(f'[{epoch + 1}] Validation Accuracy - Cross-to-Dot: {average_val_accuracy_cross_to_dot:.4f}')\n",
        "\n",
        "            if average_val_accuracy_cross_to_dot > best_val_accuracy:\n",
        "                best_val_accuracy = average_val_accuracy_cross_to_dot\n",
        "                early_stop_counter = 0\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "\n",
        "            if early_stop_counter >= patience:\n",
        "                print(\"Early stopping! Validation accuracy did not improve for the last {} epochs.\".format(patience))\n",
        "                break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return best_val_accuracy\n",
        "\n",
        "# Create a study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print the best trial\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mBeeF3LdF6kb",
        "outputId": "9d2e6601-cff8-4570-ac5d-d5541dbd3dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-26 17:14:48,399] A new study created in memory with name: no-name-debcfae6-7d32-409a-894f-5e0777d3e541\n",
            "<ipython-input-17-e3a2d4e3b2ad>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
            "<ipython-input-17-e3a2d4e3b2ad>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Cross-to-Dot Average Accuracy: 0.0460\n",
            "[1] Validation Accuracy - Cross-to-Dot: 0.1354\n",
            "[2] Cross-to-Dot Average Accuracy: 0.1431\n",
            "[2] Validation Accuracy - Cross-to-Dot: 0.1308\n",
            "[3] Cross-to-Dot Average Accuracy: 0.1611\n",
            "[3] Validation Accuracy - Cross-to-Dot: 0.1600\n",
            "[4] Cross-to-Dot Average Accuracy: 0.1733\n",
            "[4] Validation Accuracy - Cross-to-Dot: 0.1618\n",
            "[5] Cross-to-Dot Average Accuracy: 0.1743\n",
            "[5] Validation Accuracy - Cross-to-Dot: 0.1619\n",
            "[6] Cross-to-Dot Average Accuracy: 0.1743\n",
            "[6] Validation Accuracy - Cross-to-Dot: 0.1619\n",
            "[7] Cross-to-Dot Average Accuracy: 0.1743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-26 17:33:29,957] Trial 0 finished with value: 0.1618652820587158 and parameters: {'lr': 0.0037986434408371333, 'weight_decay': 2.8692489739081363e-05, 'batch_size': 16}. Best is trial 0 with value: 0.1618652820587158.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7] Validation Accuracy - Cross-to-Dot: 0.1619\n",
            "Early stopping! Validation accuracy did not improve for the last 2 epochs.\n",
            "[1] Cross-to-Dot Average Accuracy: 0.0020\n",
            "[1] Validation Accuracy - Cross-to-Dot: 0.0000\n",
            "[2] Cross-to-Dot Average Accuracy: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-26 17:37:49,211] Trial 1 finished with value: 0.0 and parameters: {'lr': 0.07676231496999499, 'weight_decay': 0.00017136367870661758, 'batch_size': 8}. Best is trial 0 with value: 0.1618652820587158.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2] Validation Accuracy - Cross-to-Dot: 0.0000\n",
            "Early stopping! Validation accuracy did not improve for the last 2 epochs.\n",
            "[1] Cross-to-Dot Average Accuracy: 0.0000\n",
            "[1] Validation Accuracy - Cross-to-Dot: 0.0000\n",
            "[2] Cross-to-Dot Average Accuracy: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-26 17:42:14,941] Trial 2 finished with value: 0.0 and parameters: {'lr': 0.06974067639281496, 'weight_decay': 0.03512498992038035, 'batch_size': 4}. Best is trial 0 with value: 0.1618652820587158.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2] Validation Accuracy - Cross-to-Dot: 0.0000\n",
            "Early stopping! Validation accuracy did not improve for the last 2 epochs.\n",
            "[1] Cross-to-Dot Average Accuracy: 0.1228\n",
            "[1] Validation Accuracy - Cross-to-Dot: 0.1785\n",
            "[2] Cross-to-Dot Average Accuracy: 0.1845\n",
            "[2] Validation Accuracy - Cross-to-Dot: 0.1734\n",
            "[3] Cross-to-Dot Average Accuracy: 0.1832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-26 17:48:47,042] Trial 3 finished with value: 0.17852095553749486 and parameters: {'lr': 6.431601925810435e-05, 'weight_decay': 0.0003268484475670201, 'batch_size': 8}. Best is trial 3 with value: 0.17852095553749486.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3] Validation Accuracy - Cross-to-Dot: 0.1736\n",
            "Early stopping! Validation accuracy did not improve for the last 2 epochs.\n",
            "[1] Cross-to-Dot Average Accuracy: 0.1538\n",
            "[1] Validation Accuracy - Cross-to-Dot: 0.1404\n",
            "[2] Cross-to-Dot Average Accuracy: 0.4033\n",
            "[2] Validation Accuracy - Cross-to-Dot: 0.4321\n",
            "[3] Cross-to-Dot Average Accuracy: 0.4362\n",
            "[3] Validation Accuracy - Cross-to-Dot: 0.4226\n",
            "[4] Cross-to-Dot Average Accuracy: 0.4374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-26 17:57:29,289] Trial 4 finished with value: 0.4320603671826814 and parameters: {'lr': 0.001157028737328991, 'weight_decay': 0.05528001778458196, 'batch_size': 8}. Best is trial 4 with value: 0.4320603671826814.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4] Validation Accuracy - Cross-to-Dot: 0.4239\n",
            "Early stopping! Validation accuracy did not improve for the last 2 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-06-26 17:57:30,740] Trial 5 failed with parameters: {'lr': 0.00010607834305447832, 'weight_decay': 0.00032910329842873585, 'batch_size': 32} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1024.00 MiB. GPU ').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-17-e3a2d4e3b2ad>\", line 37, in objective\n",
            "    output_cross_to_dot = model(cross[0].float().to(device))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"<ipython-input-16-a0f6bc1a620c>\", line 131, in forward\n",
            "    out7 = self.conv7(out6 + out_f)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU \n",
            "[W 2024-06-26 17:57:30,743] Trial 5 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e3a2d4e3b2ad>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Create a study and optimize the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Print the best trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e3a2d4e3b2ad>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0moutput_cross_to_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mloss_cross_to_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_cross_to_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss_cross_to_dot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-a0f6bc1a620c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mout5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mout6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mout7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout6\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mout8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout7\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mout9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout8\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CNNP().to(device)\n",
        "# print(model)\n",
        "\n",
        "# criterion = nn.MSELoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
        "\n",
        "# epochs = 50\n",
        "# batch_size = 4\n",
        "\n",
        "# best_val_accuracy = 0.0\n",
        "# patience = 2\n",
        "# early_stop_counter = 0\n",
        "\n",
        "# model.train()\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     total_accuracy_cross_to_dot = 0\n",
        "#     total_accuracy_dot_to_cross = 0\n",
        "\n",
        "#     if epoch % 5 == 0:\n",
        "#         # Save model parameters every 20 epochs\n",
        "#         torch.save(model.state_dict(), '/content/drive/MyDrive/PROPOSED_SACNN/model_parameter/model_state.pthram' + str(epoch) + '.pth')\n",
        "\n",
        "#     for i, (cross, dot) in enumerate(train_loader):\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Train for cross-to-dot complexity pairs\n",
        "#         output_cross_to_dot = model(cross[0].float().to(device))\n",
        "#         loss_cross_to_dot = criterion(output_cross_to_dot, dot[0].float().to(device))\n",
        "#         loss_cross_to_dot.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Compute training accuracy for cross-to-dot complexity pairs\n",
        "#         predictions_cross_to_dot = torch.round(output_cross_to_dot).squeeze().float()\n",
        "#         correct_cross_to_dot = torch.eq(predictions_cross_to_dot, dot[0].float().to(device).squeeze()).sum().item()\n",
        "#         accuracy_cross_to_dot_batch = correct_cross_to_dot / (batch_size * 512 * 512)\n",
        "#         total_accuracy_cross_to_dot += accuracy_cross_to_dot_batch\n",
        "\n",
        "#         # Similarly, train for dot-to-cross complexity pairs (modify as needed)\n",
        "\n",
        "#     average_accuracy_cross_to_dot = total_accuracy_cross_to_dot / len(train_loader)\n",
        "#     print(f'[{epoch + 1}] Cross-to-Dot Average Accuracy: {average_accuracy_cross_to_dot:.4f}')\n",
        "\n",
        "#     # Validation step\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         total_val_accuracy_cross_to_dot = 0\n",
        "\n",
        "#         for val_cross_img, val_dot_img in val_loader:\n",
        "#             val_output_cross_to_dot = model(val_cross_img[0].float().to(device))\n",
        "#             val_loss_cross_to_dot = criterion(val_output_cross_to_dot, val_dot_img[0].float().to(device))\n",
        "\n",
        "#             val_predictions_cross_to_dot = torch.round(val_output_cross_to_dot).squeeze().float()\n",
        "#             val_correct_cross_to_dot = torch.eq(val_predictions_cross_to_dot, val_dot_img[0].float().to(device).squeeze()).sum().item()\n",
        "#             val_accuracy_cross_to_dot = val_correct_cross_to_dot / (batch_size * 512 * 512)\n",
        "\n",
        "#             total_val_accuracy_cross_to_dot += val_accuracy_cross_to_dot\n",
        "\n",
        "#         average_val_accuracy_cross_to_dot = total_val_accuracy_cross_to_dot / len(val_loader)\n",
        "#         print(f'[{epoch + 1}] Validation Accuracy - Cross-to-Dot: {average_val_accuracy_cross_to_dot:.4f}')\n",
        "\n",
        "#         # Check for improvement in validation accuracy\n",
        "#         if average_val_accuracy_cross_to_dot > best_val_accuracy:\n",
        "#             best_val_accuracy = average_val_accuracy_cross_to_dot\n",
        "#             early_stop_counter = 0\n",
        "#         else:\n",
        "#             early_stop_counter += 1\n",
        "\n",
        "#         # Check for early stopping\n",
        "#         if early_stop_counter >= patience:\n",
        "#             print(\"Early stopping! Validation accuracy did not improve for the last {} epochs.\".format(patience))\n",
        "#             break\n",
        "\n",
        "#     scheduler.step()"
      ],
      "metadata": {
        "id": "m1UDzv3sJ5p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#saving the model Weights"
      ],
      "metadata": {
        "id": "nsA8aOQgLn5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrmN1t9ZpywJ"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),'/content/drive/MyDrive/PROPOSED_ACNN/model_parameter/model_state.pthpred.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cC29nGYtLqyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://)#New Mutli attention\n"
      ],
      "metadata": {
        "id": "lom002qirOeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "\n",
        "  def __init__(self,inplanes):\n",
        "    super(SelfAttention,self).__init__()\n",
        "    self.inplanes = inplanes\n",
        "    # theta transform\n",
        "    self.theta = nn.Conv2d(self.inplanes,self.inplanes//2,1)\n",
        "    # phi transform\n",
        "    self.phi = nn.Sequential(nn.Conv2d(self.inplanes,self.inplanes//2,1),\n",
        "                             # nn.MaxPool2d(2,2)\n",
        "                             )\n",
        "    # function g\n",
        "    self.g_func = nn.Sequential(nn.Conv2d(self.inplanes,self.inplanes//2,1),\n",
        "                                # nn.MaxPool2d(2,2)\n",
        "                                )\n",
        "\n",
        "    # w transform to match the channel\n",
        "    self.w = nn.Conv2d(self.inplanes//2,self.inplanes,1)\n",
        "\n",
        "  def forward(self,xs):\n",
        "\n",
        "    theta = self.theta(xs)\n",
        "    N,C,W,H = theta.size()\n",
        "    theta = theta.view(N,C,H*W).transpose(2,1)\n",
        "    # print(theta.shape)\n",
        "    phi = self.phi(xs)\n",
        "    phi = phi.view(N,C,-1)\n",
        "    # compute attention\n",
        "    attention = theta.bmm(phi)\n",
        "    assert attention.size()==(N,H*W,H*W)\n",
        "    attention = nn.functional.softmax(attention,dim=-1)\n",
        "    # g transform\n",
        "    g = self.g_func(xs)\n",
        "    g = g.view(N,C,-1)\n",
        "    # final response\n",
        "    response = g.bmm(attention.transpose(2,1))\n",
        "    response = response.view(N,C,W,H)\n",
        "    # matching channel\n",
        "    response = self.w(response)\n",
        "    output = response + xs\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "i5cqkuBdrSsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MA(nn.Module):\n",
        "    def __init__(self, inplanes):\n",
        "        super(MA, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "\n",
        "        # Define attention modules for each convolutional layer\n",
        "        self.attention2 = SelfAttention(inplanes)\n",
        "        self.attention3 = SelfAttention(inplanes)\n",
        "        self.attention4 = SelfAttention(inplanes)\n",
        "        self.attention5 = SelfAttention(inplanes)\n",
        "        self.attention6 = SelfAttention(inplanes)\n",
        "        self.attention7 = SelfAttention(inplanes)\n",
        "        self.attention8 = SelfAttention(inplanes)\n",
        "        self.attention9 = SelfAttention(inplanes)\n",
        "        self.attention10 = SelfAttention(inplanes)\n",
        "\n",
        "    def forward(self, xs):\n",
        "        # Apply attention to each convolutional layer\n",
        "        out2 = self.attention2(xs)\n",
        "        out3 = self.attention3(xs)\n",
        "        out4 = self.attention4(xs)\n",
        "        out5 = self.attention5(xs)\n",
        "        out6 = self.attention6(xs)\n",
        "        out7 = self.attention7(xs)\n",
        "        out8 = self.attention8(xs)\n",
        "        out9 = self.attention9(xs)\n",
        "        out10 = self.attention10(xs)\n",
        "\n",
        "        return out10"
      ],
      "metadata": {
        "id": "_xqCPL9BrYPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNP, self).__init__()\n",
        "        channel = 32\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(1, channel, 5, 1, padding=2),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(1, channel, 7, 1, padding=3),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv7 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv8 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv9 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.conv10 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, 1, 3, 1, padding=1),\n",
        "        )\n",
        "        # Define other convolution layers\n",
        "\n",
        "        self.multi_attention = MultiAttention(channel)\n",
        "        self.pool = nn.AvgPool2d(2, 2)\n",
        "        self.resize = transforms.Resize(512)\n",
        "\n",
        "    def forward(self, images):\n",
        "        out2 = self.conv2(images)\n",
        "        out3 = self.conv3(images)\n",
        "        pool2 = self.pool(self.pool(self.pool(out2)))\n",
        "        pool3 = self.pool(self.pool(self.pool(out3)))\n",
        "\n",
        "        attn2 = self.multi_attention(pool2)\n",
        "        attn3 = self.multi_attention(pool3)\n",
        "\n",
        "        attn2 = self.resize(attn2)\n",
        "        attn3 = self.resize(attn3)\n",
        "\n",
        "        out_f = out3 + attn3 + out2 + attn2\n",
        "        out4 = self.conv4(out_f)\n",
        "        out5 = self.conv5(out4 + out_f)\n",
        "        out6 = self.conv6(out4 + out_f)\n",
        "        out7 = self.conv7(out6 + out_f)\n",
        "        out8 = self.conv8(out7 + out_f)\n",
        "        out9 = self.conv9(out8 + out_f)\n",
        "        out10 = self.conv10(out9 + out_f)\n",
        "\n",
        "        return out10"
      ],
      "metadata": {
        "id": "rFpl9Nfdrbol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3c2diIufUkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEW CNN ARCHITECTURE"
      ],
      "metadata": {
        "id": "Lmp0gSzS_1R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init"
      ],
      "metadata": {
        "id": "RyiISt8aCmB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MHA(nn.Module):\n",
        "    def __init__(self, inplanes, num_heads=8):\n",
        "        super(MHA, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.num_heads = num_heads\n",
        "        assert self.inplanes % self.num_heads == 0, \"inplanes must be divisible by num_heads\"\n",
        "\n",
        "        self.head_dim = self.inplanes // self.num_heads\n",
        "\n",
        "        # Define linear transformations for queries, keys, and values for each head\n",
        "        self.query_heads = nn.ModuleList([nn.Conv2d(self.inplanes, self.head_dim, 1) for _ in range(self.num_heads)])\n",
        "        self.key_heads = nn.ModuleList([nn.Conv2d(self.inplanes, self.head_dim, 1) for _ in range(self.num_heads)])\n",
        "        self.value_heads = nn.ModuleList([nn.Conv2d(self.inplanes, self.head_dim, 1) for _ in range(self.num_heads)])\n",
        "\n",
        "        # Final linear transformation\n",
        "        self.w = nn.Conv2d(self.inplanes, self.inplanes, 1)\n",
        "\n",
        "    def forward(self, xs):\n",
        "        # Apply linear transformations for query, key, value\n",
        "        queries = [self.query_heads[i](xs) for i in range(self.num_heads)]\n",
        "        keys = [self.key_heads[i](xs) for i in range(self.num_heads)]\n",
        "        values = [self.value_heads[i](xs) for i in range(self.num_heads)]\n",
        "\n",
        "        # Prepare query, key, value tensors\n",
        "        queries = [query.view(query.size(0), self.head_dim, -1) for query in queries]\n",
        "        keys = [key.view(key.size(0), self.head_dim, -1) for key in keys]\n",
        "        values = [value.view(value.size(0), self.head_dim, -1) for value in values]\n",
        "\n",
        "        # Compute attention scores\n",
        "        attention_scores = [torch.matmul(queries[i], keys[i].transpose(-2, -1)) / (self.head_dim ** 0.5) for i in range(self.num_heads)]\n",
        "        attention_scores = [F.softmax(score, dim=-1) for score in attention_scores]\n",
        "\n",
        "        # Apply attention to values\n",
        "        head_outputs = [torch.matmul(attention_scores[i], values[i]) for i in range(self.num_heads)]\n",
        "        head_outputs = [output.view(output.size(0), self.head_dim, xs.size(2), xs.size(3)) for output in head_outputs]\n",
        "\n",
        "        # Concatenate head outputs along the channel dimension\n",
        "        multi_head_output = torch.cat(head_outputs, dim=1)\n",
        "\n",
        "        # Final linear transformation\n",
        "        multi_head_output = self.w(multi_head_output)\n",
        "\n",
        "        # Add residual connection\n",
        "        output = xs + multi_head_output\n",
        "        return output\n",
        "\n",
        "\n",
        "class CNNP(nn.Module):\n",
        "    def __init__(self, channel=32):\n",
        "        super(CNNP, self).__init__()\n",
        "        self.channel = channel\n",
        "\n",
        "        # Define convolutional layers\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(1, channel, 5, 1, padding=2),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(1, channel, 7, 1, padding=3),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(channel, channel, 3, 1, padding=1),\n",
        "        )\n",
        "        self.conv5 = nn.Conv2d(channel, 1, 3, 1, padding=1)\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.attn = MultiHeadAttention(channel, num_heads=8)\n",
        "        self.pool = nn.AvgPool2d(2, 2)\n",
        "        self.resize = transforms.Resize(512)\n",
        "\n",
        "    def forward(self, images):\n",
        "        # CNN layers\n",
        "        out2 = self.conv2(images)\n",
        "        out3 = self.conv3(images)\n",
        "        pool2 = self.pool(self.pool(self.pool(out2)))\n",
        "        pool3 = self.pool(self.pool(self.pool(out3)))\n",
        "\n",
        "        # Apply multi-head attention\n",
        "        attn2 = self.attn(pool2)\n",
        "        attn3 = self.attn(pool3)\n",
        "        attn2 = self.resize(attn2)\n",
        "        attn3 = self.resize(attn3)\n",
        "\n",
        "        # Final feature fusion\n",
        "        out_f = out3 + attn3 + out2 + attn2\n",
        "        out4 = self.conv4(out_f)\n",
        "        out5 = self.conv5(out4)\n",
        "\n",
        "        return out5"
      ],
      "metadata": {
        "id": "Ms3my_wi_0px"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}